// Copyright 2026 The CUE Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package main

import (
	"bytes"
	"fmt"
	"os"
	"path/filepath"
	"regexp"
	"slices"
	"strconv"
	"strings"
	"text/template/parse"

	"cuelang.org/go/cue"
	"cuelang.org/go/cue/cuecontext"
	"cuelang.org/go/cue/format"
	"cuelang.org/go/cue/parser"
	cueyaml "cuelang.org/go/encoding/yaml"
	"gopkg.in/yaml.v3"
)

const generatedHeader = "// Code generated by helm2cue; DO NOT EDIT.\n\n"

// chartMetadata holds the parsed contents of Chart.yaml.
type chartMetadata struct {
	Name       string `yaml:"name"`
	Version    string `yaml:"version"`
	AppVersion string `yaml:"appVersion"`
}

// templateResult holds the conversion result for a single template file.
type templateResult struct {
	fieldName string
	filename  string
	result    *convertResult
}

// ChartOptions configures chart conversion behavior.
type ChartOptions struct {
	// AllowDuplicateHelpers controls how conflicting helper template
	// definitions are handled. When false (the default), identical
	// duplicate definitions are silently deduplicated but conflicting
	// definitions cause an error. When true, the last definition wins
	// (with a warning to stderr).
	AllowDuplicateHelpers bool

	// Logf, if non-nil, receives warnings and the summary line that
	// would otherwise be printed to stderr.
	Logf func(format string, args ...any)
}

// ConvertChart converts a Helm chart directory to a CUE module in outDir.
func ConvertChart(chartDir, outDir string, opts ChartOptions) error {
	// 1. Parse Chart.yaml.
	metaData, err := os.ReadFile(filepath.Join(chartDir, "Chart.yaml"))
	if err != nil {
		return fmt.Errorf("reading Chart.yaml: %w", err)
	}
	var meta chartMetadata
	if err := yaml.Unmarshal(metaData, &meta); err != nil {
		return fmt.Errorf("parsing Chart.yaml: %w", err)
	}
	if meta.Name == "" {
		return fmt.Errorf("chart.yaml: missing name")
	}

	pkgName := sanitizePackageName(meta.Name)

	// 2. Collect helpers: templates/**/*.tpl + charts/*/templates/**/*.tpl
	var helperData [][]byte
	var tplFiles []string
	filepath.WalkDir(filepath.Join(chartDir, "templates"), func(path string, d os.DirEntry, err error) error {
		if err != nil || d.IsDir() {
			return nil
		}
		if filepath.Ext(path) == ".tpl" {
			tplFiles = append(tplFiles, path)
		}
		return nil
	})
	// Subchart helpers.
	subchartsDir := filepath.Join(chartDir, "charts")
	if entries, err := os.ReadDir(subchartsDir); err == nil {
		for _, e := range entries {
			if !e.IsDir() {
				continue
			}
			filepath.WalkDir(filepath.Join(subchartsDir, e.Name(), "templates"), func(path string, d os.DirEntry, err error) error {
				if err != nil || d.IsDir() {
					return nil
				}
				if filepath.Ext(path) == ".tpl" {
					tplFiles = append(tplFiles, path)
				}
				return nil
			})
		}
	}
	slices.Sort(tplFiles)
	for _, f := range tplFiles {
		data, err := os.ReadFile(f)
		if err != nil {
			return fmt.Errorf("reading helper %s: %w", f, err)
		}
		helperData = append(helperData, data)
	}

	// 3. Parse all helpers once.
	treeSet, helperFileNames, err := parseHelpers(helperData, opts.AllowDuplicateHelpers)
	if err != nil {
		return fmt.Errorf("parsing helpers: %w", err)
	}

	// 4. Collect templates: templates/**/*.yaml, templates/**/*.yml (skip .tpl, NOTES.txt).
	templatesDir := filepath.Join(chartDir, "templates")
	var templateFiles []string
	filepath.WalkDir(templatesDir, func(path string, d os.DirEntry, err error) error {
		if err != nil || d.IsDir() {
			return nil
		}
		ext := filepath.Ext(path)
		if ext != ".yaml" && ext != ".yml" {
			return nil
		}
		if filepath.Base(path) == "NOTES.txt" {
			return nil
		}
		templateFiles = append(templateFiles, path)
		return nil
	})
	slices.Sort(templateFiles)

	cfg := HelmConfig()

	// 5. Convert each template.
	var results []templateResult
	var warnings []string
	totalDocs := 0

	for _, tmplPath := range templateFiles {
		// Use path relative to templates/ for display and field naming,
		// so subdirectory templates get unique names (e.g. alertmanager/service.yaml
		// becomes alertmanager_service, distinct from prometheus/service.yaml).
		relPath, _ := filepath.Rel(templatesDir, tmplPath)
		if relPath == "" {
			relPath = filepath.Base(tmplPath)
		}

		content, err := os.ReadFile(tmplPath)
		if err != nil {
			warnings = append(warnings, fmt.Sprintf("skipping %s: %v", relPath, err))
			totalDocs++
			continue
		}

		fieldName := templateFieldName(relPath)
		docs := splitTemplateDocuments(content, treeSet)
		if docs == nil {
			docs = splitYAMLDocuments(content)
		}

		// Convert each document fragment.
		var docResults []*convertResult
		allOK := true
		for i, doc := range docs {
			totalDocs++
			docFieldName := fieldName
			if len(docs) > 1 {
				docFieldName = fmt.Sprintf("%s_%d", fieldName, i)
			}
			templateName := "chart_" + docFieldName

			r, err := convertStructured(cfg, doc, templateName, treeSet, helperFileNames)
			if err != nil {
				warnings = append(warnings, fmt.Sprintf("skipping %s (doc %d): %v", relPath, i, err))
				allOK = false
				break
			}

			if err := validateTemplateBody(r); err != nil {
				warnings = append(warnings, fmt.Sprintf("skipping %s (doc %d): %v", relPath, i, err))
				allOK = false
				break
			}

			docResults = append(docResults, r)
		}
		if !allOK || len(docResults) == 0 {
			continue
		}

		// Merge all docs for this template file into a single
		// list-based result.
		merged := mergeChartDocResults(docResults)
		results = append(results, templateResult{fieldName, relPath, merged})
	}

	if len(results) == 0 {
		return fmt.Errorf("no templates converted successfully")
	}

	// 6. Merge across all results.
	mergedContextObjects := make(map[string]bool)
	mergedFieldRefs := make(map[string][][]string)
	mergedRequiredRefs := make(map[string][][]string)
	mergedRangeRefs := make(map[string][][]string)
	mergedDefaults := make(map[string][]fieldDefault)
	needsNonzero := false
	mergedUsedHelpers := make(map[string]HelperDef)
	hasDynamicInclude := false

	// Helper info comes from first result (all share the same treeSet).
	firstResult := results[0].result

	for _, tr := range results {
		r := tr.result
		for k := range r.usedContextObjects {
			mergedContextObjects[k] = true
		}
		for k, v := range r.fieldRefs {
			mergedFieldRefs[k] = append(mergedFieldRefs[k], v...)
		}
		for k, v := range r.requiredRefs {
			mergedRequiredRefs[k] = append(mergedRequiredRefs[k], v...)
		}
		for k, v := range r.rangeRefs {
			mergedRangeRefs[k] = append(mergedRangeRefs[k], v...)
		}
		for k, v := range r.defaults {
			mergedDefaults[k] = append(mergedDefaults[k], v...)
		}
		if r.needsNonzero {
			needsNonzero = true
		}
		for k, v := range r.usedHelpers {
			mergedUsedHelpers[k] = v
		}
		if r.hasDynamicInclude {
			hasDynamicInclude = true
		}
	}

	// 7. Create output directory structure.
	if err := os.MkdirAll(filepath.Join(outDir, "cue.mod"), 0o755); err != nil {
		return fmt.Errorf("creating output directory: %w", err)
	}

	// Write cue.mod/module.cue.
	moduleCUE := generatedHeader + fmt.Sprintf("module: \"helm.local/%s\"\nlanguage: {\n\tversion: \"v0.16.0\"\n}\n", meta.Name)
	if err := os.WriteFile(filepath.Join(outDir, "cue.mod", "module.cue"), []byte(moduleCUE), 0o644); err != nil {
		return fmt.Errorf("writing module.cue: %w", err)
	}

	// Write helpers.cue.
	if err := writeHelpersCUE(outDir, pkgName, firstResult, needsNonzero, mergedUsedHelpers, hasDynamicInclude); err != nil {
		return err
	}

	// Build the values schema and validate it.
	schemaCUE := buildValuesSchemaCUE(mergedFieldRefs["Values"], mergedDefaults["Values"], mergedRequiredRefs["Values"], mergedRangeRefs["Values"])
	var valWarnings []string
	if err := validateSchema(schemaCUE, cfg.ContextObjects); err != nil {
		valWarnings = append(valWarnings, fmt.Sprintf("values schema inconsistency: %v", err))
	}

	// Read values.yaml early for both validation and later copying.
	valuesPath := filepath.Join(chartDir, "values.yaml")
	valuesData, valuesErr := os.ReadFile(valuesPath)
	if valuesErr == nil {
		if err := validateValuesAgainstSchema(schemaCUE, valuesData, cfg.ContextObjects); err != nil {
			valWarnings = append(valWarnings, fmt.Sprintf("values.yaml does not satisfy inferred schema: %v", err))
		}
	}

	// Write values.cue.
	if err := writeValuesCUE(outDir, pkgName, schemaCUE); err != nil {
		return err
	}

	// Write data.cue (embeds values.yaml and release.yaml via @extern(embed)).
	if err := writeDataCUE(outDir, pkgName); err != nil {
		return err
	}

	// Write context.cue.
	if err := writeContextCUE(outDir, pkgName, meta, mergedContextObjects); err != nil {
		return err
	}

	// Write per-template .cue files.
	for _, tr := range results {
		if err := writeTemplateCUE(outDir, pkgName, tr.fieldName, tr.result); err != nil {
			return err
		}
	}

	// Write results.cue (aggregates all templates into a list for yaml.MarshalStream).
	if err := writeResultsCUE(outDir, pkgName, results); err != nil {
		return err
	}

	// 8. Copy values.yaml and write empty release.yaml placeholder.
	if valuesErr == nil {
		if err := os.WriteFile(filepath.Join(outDir, "values.yaml"), valuesData, 0o644); err != nil {
			return fmt.Errorf("copying values.yaml: %w", err)
		}
	}
	if err := os.WriteFile(filepath.Join(outDir, "release.yaml"), []byte{}, 0o644); err != nil {
		return fmt.Errorf("writing release.yaml: %w", err)
	}

	// 9. Print summary to stderr (or opts.Logf if set).
	logf := opts.Logf
	if logf == nil {
		logf = func(format string, args ...any) {
			fmt.Fprintf(os.Stderr, format, args...)
		}
	}
	for _, w := range warnings {
		logf("warning: %s\n", w)
	}
	for _, w := range valWarnings {
		logf("warning: %s\n", w)
	}
	logf("converted %d/%d templates from %s\n",
		len(results), totalDocs, meta.Name)

	return nil
}

var (
	yamlDocSep    = regexp.MustCompile(`(?m)^---\s*$`)
	yamlLeadingRe = regexp.MustCompile(`(?m)^(\s*#[^\n]*|\s*)\n`)
)

// splitYAMLDocuments splits raw template bytes on YAML document
// separator lines (^---) and strips leading blank lines and YAML
// comment lines from each fragment. Empty fragments (from a leading
// ---) are dropped. Single-document files return one fragment.
func splitYAMLDocuments(content []byte) [][]byte {
	parts := yamlDocSep.Split(string(content), -1)
	var docs [][]byte
	for _, p := range parts {
		// Strip leading blank/comment lines.
		s := p
		for {
			loc := yamlLeadingRe.FindStringIndex(s)
			if loc == nil || loc[0] != 0 {
				break
			}
			s = s[loc[1]:]
		}
		s = strings.TrimRight(s, "\n\t ")
		if s == "" {
			continue
		}
		docs = append(docs, []byte(s+"\n"))
	}
	return docs
}

// writeCUEFile formats CUE source and writes it to path.
func writeCUEFile(path string, data []byte) error {
	formatted, err := format.Source(data)
	if err != nil {
		return fmt.Errorf("formatting %s: %w", filepath.Base(path), err)
	}
	return os.WriteFile(path, formatted, 0o644)
}

// writeHelpersCUE writes helpers.cue with helper definitions.
func writeHelpersCUE(outDir, pkgName string, r *convertResult, needsNonzero bool, usedHelpers map[string]HelperDef, hasDynamicInclude bool) error {
	var buf bytes.Buffer
	buf.WriteString(generatedHeader)
	fmt.Fprintf(&buf, "package %s\n\n", pkgName)

	// Collect all imports needed by helper expressions and built-in definitions.
	helperImports := make(map[string]bool)
	if needsNonzero {
		helperImports["struct"] = true
	}
	for _, h := range usedHelpers {
		for _, pkg := range h.Imports {
			helperImports[pkg] = true
		}
	}
	for _, name := range r.helperOrder {
		cueName := r.helperExprs[name]
		if cueExpr, ok := r.helpers[cueName]; ok {
			for pkg := range r.imports {
				shortName := pkg
				if idx := strings.LastIndex(pkg, "/"); idx >= 0 {
					shortName = pkg[idx+1:]
				}
				if strings.Contains(cueExpr, shortName+".") {
					helperImports[pkg] = true
				}
			}
		}
	}

	if len(helperImports) > 0 {
		var pkgs []string
		for pkg := range helperImports {
			pkgs = append(pkgs, pkg)
		}
		slices.Sort(pkgs)
		if len(pkgs) == 1 {
			fmt.Fprintf(&buf, "import %q\n\n", pkgs[0])
		} else {
			buf.WriteString("import (\n")
			for _, pkg := range pkgs {
				fmt.Fprintf(&buf, "\t%q\n", pkg)
			}
			buf.WriteString(")\n\n")
		}
	}

	if needsNonzero {
		buf.WriteString(nonzeroDef)
		buf.WriteString("\n")
	}

	for _, h := range usedHelpers {
		buf.WriteString(h.Def)
		buf.WriteString("\n")
	}

	for _, name := range r.helperOrder {
		cueName := r.helperExprs[name]
		if cueExpr, ok := r.helpers[cueName]; ok {
			// Validate this helper in isolation before including it.
			if err := validateHelperExpr(cueExpr, r.imports); err != nil {
				fmt.Fprintf(&buf, "%s: _\n", cueName)
			} else {
				fmt.Fprintf(&buf, "%s: %s\n", cueName, cueExpr)
			}
		} else {
			fmt.Fprintf(&buf, "%s: _\n", cueName)
		}
	}

	if len(r.undefinedHelpers) > 0 {
		var undefs []string
		for _, cueName := range r.undefinedHelpers {
			if _, defined := r.helpers[cueName]; !defined {
				undefs = append(undefs, cueName)
			}
		}
		slices.Sort(undefs)
		for _, cueName := range undefs {
			fmt.Fprintf(&buf, "%s: _\n", cueName)
		}
	}

	if hasDynamicInclude {
		type helperEntry struct {
			origName string
			cueName  string
		}
		var entries []helperEntry
		for _, origName := range r.helperOrder {
			cueName := r.helperExprs[origName]
			entries = append(entries, helperEntry{origName, cueName})
		}
		for origName, cueName := range r.undefinedHelpers {
			entries = append(entries, helperEntry{origName, cueName})
		}
		slices.SortFunc(entries, func(a, b helperEntry) int {
			return strings.Compare(a.origName, b.origName)
		})
		buf.WriteString("_helpers: {\n")
		for _, e := range entries {
			fmt.Fprintf(&buf, "\t%s: %s\n", strconv.Quote(e.origName), e.cueName)
		}
		buf.WriteString("}\n")
	}

	return writeCUEFile(filepath.Join(outDir, "helpers.cue"), buf.Bytes())
}

// buildValuesSchemaCUE generates the #values schema block (without a package
// header) from the merged field references, defaults, and required refs.
func buildValuesSchemaCUE(refs [][]string, defs []fieldDefault, requiredRefs [][]string, rangeRefs [][]string) []byte {
	var buf bytes.Buffer
	if len(refs) == 0 && len(defs) == 0 {
		buf.WriteString("#values: _\n")
	} else {
		buf.WriteString("#values: {\n")
		root := buildFieldTree(refs, defs, requiredRefs, rangeRefs)
		emitFieldNodes(&buf, root.children, 1)
		writeIndent(&buf, 1)
		buf.WriteString("...\n")
		buf.WriteString("}\n")
	}
	return buf.Bytes()
}

// writeValuesCUE writes values.cue with the #values schema.
func writeValuesCUE(outDir, pkgName string, schemaCUE []byte) error {
	var buf bytes.Buffer
	buf.WriteString(generatedHeader)
	fmt.Fprintf(&buf, "package %s\n\n", pkgName)
	buf.Write(schemaCUE)
	return writeCUEFile(filepath.Join(outDir, "values.cue"), buf.Bytes())
}

// prependContextStubs prepends stub definitions for context objects
// (e.g. #chart: _) so that default values referencing them can be
// resolved during validation. The #values definition is skipped
// since it is already present in the schema.
func prependContextStubs(schemaCUE []byte, contextObjects map[string]string) []byte {
	if len(contextObjects) == 0 {
		return schemaCUE
	}
	var buf bytes.Buffer
	for _, cueDef := range contextObjects {
		if cueDef == "#values" {
			continue
		}
		fmt.Fprintf(&buf, "%s: _\n", cueDef)
	}
	buf.Write(schemaCUE)
	return buf.Bytes()
}

// validateSchema compiles the schema CUE and checks it for internal
// consistency using CUE's own unification. Context object stubs are
// prepended so that default values referencing other context objects
// (e.g. *#chart.Name) can be resolved.
func validateSchema(schemaCUE []byte, contextObjects map[string]string) error {
	ctx := cuecontext.New()
	v := ctx.CompileBytes(prependContextStubs(schemaCUE, contextObjects))
	if err := v.Err(); err != nil {
		return err
	}
	return v.Validate()
}

// validateValuesAgainstSchema validates that valuesYAML satisfies the
// constraints in schemaCUE. It uses CUE unification: the YAML is parsed
// into a CUE value, unified with the #values definition from the schema,
// and the result is validated.
func validateValuesAgainstSchema(schemaCUE, valuesYAML []byte, contextObjects map[string]string) error {
	ctx := cuecontext.New()
	schema := ctx.CompileBytes(prependContextStubs(schemaCUE, contextObjects))
	if err := schema.Err(); err != nil {
		return err
	}
	schemaVal := schema.LookupPath(cue.MakePath(cue.Def("values")))

	yamlFile, err := cueyaml.Extract("values.yaml", valuesYAML)
	if err != nil {
		return fmt.Errorf("parsing values.yaml: %w", err)
	}
	yamlAsCUE := ctx.BuildFile(yamlFile)

	unified := schemaVal.Unify(yamlAsCUE)
	return unified.Validate(cue.Concrete(true))
}

// writeDataCUE writes data.cue which uses @extern(embed) to embed
// values.yaml and release.yaml, with @tag(release_name) for CLI injection.
func writeDataCUE(outDir, pkgName string) error {
	var buf bytes.Buffer
	buf.WriteString(generatedHeader)
	buf.WriteString("@extern(embed)\n\n")
	fmt.Fprintf(&buf, "package %s\n\n", pkgName)
	buf.WriteString("#values:  _ @embed(file=values.yaml)\n")
	buf.WriteString("#release: _ @embed(file=release.yaml)\n")
	buf.WriteString("#release: {\n")
	buf.WriteString("\tName: _ @tag(release_name)\n")
	buf.WriteString("}\n")

	return writeCUEFile(filepath.Join(outDir, "data.cue"), buf.Bytes())
}

// writeResultsCUE writes results.cue which aggregates all template outputs
// into a single list. Each template produces a list, so results concatenates
// them using list.FlattenN.
func writeResultsCUE(outDir, pkgName string, results []templateResult) error {
	var buf bytes.Buffer
	buf.WriteString(generatedHeader)
	fmt.Fprintf(&buf, "package %s\n\n", pkgName)
	buf.WriteString("import \"list\"\n\n")
	buf.WriteString("results: list.FlattenN([\n")
	for _, tr := range results {
		fmt.Fprintf(&buf, "\t%s,\n", tr.fieldName)
	}
	buf.WriteString("], 1)\n")

	return writeCUEFile(filepath.Join(outDir, "results.cue"), buf.Bytes())
}

// writeContextCUE writes context.cue with definitions for used context objects.
func writeContextCUE(outDir, pkgName string, meta chartMetadata, usedContextObjects map[string]bool) error {
	// Only write context objects that are actually used (excluding Values, which has its own file).
	var needed []string
	for obj := range usedContextObjects {
		if obj == "Values" {
			continue
		}
		needed = append(needed, obj)
	}
	slices.Sort(needed)

	if len(needed) == 0 {
		return nil
	}

	var buf bytes.Buffer
	buf.WriteString(generatedHeader)
	fmt.Fprintf(&buf, "package %s\n\n", pkgName)

	for _, obj := range needed {
		switch obj {
		case "Release":
			buf.WriteString("#release: {\n")
			buf.WriteString("\tName: _\n")
			buf.WriteString("\tNamespace: *\"default\" | string\n")
			buf.WriteString("\tService: *\"Helm\" | string\n")
			buf.WriteString("\tIsUpgrade: *false | bool\n")
			buf.WriteString("\tIsInstall: *true | bool\n")
			buf.WriteString("\tRevision: *1 | int\n")
			buf.WriteString("}\n")
		case "Chart":
			fmt.Fprintf(&buf, "#chart: {\n")
			fmt.Fprintf(&buf, "\tName: %s\n", strconv.Quote(meta.Name))
			fmt.Fprintf(&buf, "\tVersion: %s\n", strconv.Quote(meta.Version))
			fmt.Fprintf(&buf, "\tAppVersion: %s\n", strconv.Quote(meta.AppVersion))
			fmt.Fprintf(&buf, "}\n")
		case "Capabilities":
			buf.WriteString("#capabilities: {\n")
			buf.WriteString("\tKubeVersion: {\n")
			buf.WriteString("\t\tVersion: *\"v1.28.0\" | string\n")
			buf.WriteString("\t\tMajor: *\"1\" | string\n")
			buf.WriteString("\t\tMinor: *\"28\" | string\n")
			buf.WriteString("\t}\n")
			buf.WriteString("\tAPIVersions: [...string]\n")
			buf.WriteString("}\n")
		case "Template":
			buf.WriteString("#template: {\n")
			buf.WriteString("\tName: *\"template\" | string\n")
			buf.WriteString("\tBasePath: *\"templates\" | string\n")
			buf.WriteString("}\n")
		case "Files":
			buf.WriteString("#files: _\n")
		}
	}

	return writeCUEFile(filepath.Join(outDir, "context.cue"), buf.Bytes())
}

// writeTemplateCUE writes a per-template .cue file. The body is already
// wrapped as a list by mergeChartDocResults, so we emit it directly as
// fieldName: [body].
func writeTemplateCUE(outDir, pkgName, fieldName string, r *convertResult) error {
	var buf bytes.Buffer
	buf.WriteString(generatedHeader)
	fmt.Fprintf(&buf, "package %s\n\n", pkgName)

	// Emit only imports that are actually used in this template body.
	body := strings.TrimRight(r.body, "\n")
	imports := make(map[string]bool)
	for pkg := range r.imports {
		// The CUE package name is the last path segment.
		shortName := pkg
		if idx := strings.LastIndex(pkg, "/"); idx >= 0 {
			shortName = pkg[idx+1:]
		}
		// Only include if the body references this package.
		if strings.Contains(body, shortName+".") {
			imports[pkg] = true
		}
	}

	if len(imports) > 0 {
		var pkgs []string
		for pkg := range imports {
			pkgs = append(pkgs, pkg)
		}
		slices.Sort(pkgs)
		if len(pkgs) == 1 {
			fmt.Fprintf(&buf, "import %q\n\n", pkgs[0])
		} else {
			buf.WriteString("import (\n")
			for _, pkg := range pkgs {
				fmt.Fprintf(&buf, "\t%q\n", pkg)
			}
			buf.WriteString(")\n\n")
		}
	}

	if body == "" {
		return nil
	}

	// The body from mergeChartDocResults is already the list contents.
	fmt.Fprintf(&buf, "%s: %s\n", fieldName, body)

	return writeCUEFile(filepath.Join(outDir, fieldName+".cue"), buf.Bytes())
}

// validateTemplateBody checks that a template body is syntactically valid CUE.
// It uses parser-level validation only (no evaluation), since the full context
// (imports, helpers, values) is not available for semantic checking.
func validateTemplateBody(r *convertResult) error {
	body := strings.TrimRight(r.body, "\n")
	if body == "" {
		return nil
	}

	// Build a CUE file with the body wrapped in a list element.
	var src bytes.Buffer
	indent := 0
	if len(r.topLevelGuards) > 0 {
		for _, guard := range r.topLevelGuards {
			writeIndent(&src, indent)
			fmt.Fprintf(&src, "if %s {\n", guard)
			indent++
		}
	}
	writeIndent(&src, indent)
	src.WriteString("_body: [{\n")
	for _, line := range strings.Split(body, "\n") {
		writeIndent(&src, indent+1)
		src.WriteString(line)
		src.WriteByte('\n')
	}
	writeIndent(&src, indent)
	src.WriteString("}]\n")
	for i := len(r.topLevelGuards) - 1; i >= 0; i-- {
		writeIndent(&src, i)
		src.WriteString("}\n")
	}

	_, err := parser.ParseFile("body.cue", src.Bytes())
	if err != nil && os.Getenv("HELM2CUE_DEBUG") != "" {
		fmt.Fprintf(os.Stderr, "DEBUG: CUE validation failed: %v\nsource:\n%s\n", err, src.Bytes())
	}
	return err
}

// blockWrapper records the opening/closing template text for a block
// (if/range/with) that spans a --- boundary. Fragments inside the
// block get these prepended/appended so each is independently parseable.
type blockWrapper struct {
	open    string // e.g. "{{- if .Values.enabled }}\n"
	close   string // e.g. "{{- end }}\n"
	isRange bool   // true if the block is a range (vs if/with)
}

// splitTemplateDocuments splits a template file into per-document
// fragments, handling control blocks (if/range/with) that span ---
// boundaries. It parses the whole file as a single template to find
// block structure, then splits the raw text and augments each fragment
// with enclosing block wrappers and variable definitions from earlier
// fragments.
//
// If the whole-file parse fails, it returns nil (caller should fall
// back to splitYAMLDocuments). If no --- separator is found, it
// returns nil.
func splitTemplateDocuments(content []byte, treeSet map[string]*parse.Tree) [][]byte {
	// Quick check: any --- at all?
	if !yamlDocSep.Match(content) {
		return nil
	}

	// Parse the whole file as a single template.
	tmpl := parse.New("__splitcheck__")
	tmpl.Mode = parse.SkipFuncCheck | parse.ParseComments
	// Clone treeSet to avoid polluting the shared set.
	tsCopy := make(map[string]*parse.Tree, len(treeSet))
	for k, v := range treeSet {
		tsCopy[k] = v
	}
	if _, err := tmpl.Parse(string(content), "{{", "}}", tsCopy); err != nil {
		return nil
	}
	root := tmpl.Root
	if root == nil {
		return nil
	}

	// Walk the AST to find --- separators and their block context.
	var info docSplitInfo
	info.varDefs = make(map[string]string)
	walkDocBoundaries(root.Nodes, nil, &info)

	if len(info.boundaries) == 0 {
		return nil
	}

	// Split the raw content on --- lines.
	rawDocs := splitYAMLDocuments(content)
	if len(rawDocs) <= 1 {
		return rawDocs
	}

	// Build augmented fragments.
	//
	// boundaries[i] describes the block context at the i-th ---
	// separator (between rawDocs[i] and rawDocs[i+1]).
	//
	// The raw text of each fragment already contains the original
	// template actions. When a block spans a ---, the first fragment
	// has the opener (e.g. {{if ...}}) but no closer, and the last
	// fragment has the closer ({{end}}) but no opener. So:
	//
	//   Fragment 0:     add closers for boundary[0].wrappers
	//   Fragment i>0:   add openers from boundary[i-1].wrappers
	//                   add closers from boundary[i].wrappers (if exists)
	//   Fragment last:  add openers from boundary[last].wrappers only
	//
	// Variable definitions from earlier fragments are also prepended.
	result := make([][]byte, len(rawDocs))

	// Fragment 0: may need closers if boundary[0] has wrappers.
	if len(info.boundaries) > 0 && len(info.boundaries[0].wrappers) > 0 {
		var buf bytes.Buffer
		buf.Write(rawDocs[0])
		for j := len(info.boundaries[0].wrappers) - 1; j >= 0; j-- {
			buf.WriteString(info.boundaries[0].wrappers[j].close)
		}
		result[0] = stripLeadingClean(buf.Bytes())
	} else {
		result[0] = rawDocs[0]
	}

	for i := 1; i < len(rawDocs); i++ {
		prevBIdx := i - 1
		if prevBIdx >= len(info.boundaries) {
			result[i] = rawDocs[i]
			continue
		}
		prevB := info.boundaries[prevBIdx]

		var buf bytes.Buffer
		// Prepend variable definitions from earlier documents.
		for _, vd := range prevB.varDefs {
			buf.WriteString(vd)
			buf.WriteByte('\n')
		}
		// Prepend block openers from the boundary before this fragment.
		for _, w := range prevB.wrappers {
			buf.WriteString(w.open)
		}
		buf.Write(rawDocs[i])
		// Append block closers only if there's a next boundary
		// (i.e. this isn't the last fragment) with wrappers.
		nextBIdx := i
		if nextBIdx < len(info.boundaries) {
			nextB := info.boundaries[nextBIdx]
			for j := len(nextB.wrappers) - 1; j >= 0; j-- {
				buf.WriteString(nextB.wrappers[j].close)
			}
		}

		result[i] = stripLeadingClean(buf.Bytes())
	}

	return result
}

// stripLeadingClean strips leading blank/comment lines and trailing
// whitespace, like splitYAMLDocuments does for each fragment.
func stripLeadingClean(data []byte) []byte {
	s := string(data)
	for {
		loc := yamlLeadingRe.FindStringIndex(s)
		if loc == nil || loc[0] != 0 {
			break
		}
		s = s[loc[1]:]
	}
	s = strings.TrimRight(s, "\n\t ")
	if s == "" {
		return data
	}
	return []byte(s + "\n")
}

// docBoundary records the block context and variable definitions at a
// single --- separator.
type docBoundary struct {
	wrappers []blockWrapper // enclosing blocks, outermost first
	varDefs  []string       // "{{$var := expr}}" lines to prepend
}

// docSplitInfo accumulates state while walking the AST for --- boundaries.
type docSplitInfo struct {
	boundaries []docBoundary
	varDefs    map[string]string // accumulated $var definitions
}

// walkDocBoundaries walks a list of AST nodes looking for TextNodes
// containing ---. wrappers is the stack of enclosing blocks.
func walkDocBoundaries(nodes []parse.Node, wrappers []blockWrapper, info *docSplitInfo) {
	for _, node := range nodes {
		switch n := node.(type) {
		case *parse.TextNode:
			// Check if this text contains --- separators.
			text := string(n.Text)
			locs := yamlDocSep.FindAllStringIndex(text, -1)
			for range locs {
				// Snapshot current variable definitions.
				var vds []string
				// Collect in sorted order for determinism.
				var keys []string
				for k := range info.varDefs {
					keys = append(keys, k)
				}
				slices.Sort(keys)
				for _, k := range keys {
					vds = append(vds, info.varDefs[k])
				}
				info.boundaries = append(info.boundaries, docBoundary{
					wrappers: slices.Clone(wrappers),
					varDefs:  vds,
				})
			}

		case *parse.ActionNode:
			// Check for variable declarations: {{$var := expr}}.
			if n.Pipe != nil && len(n.Pipe.Decl) > 0 && !n.Pipe.IsAssign {
				for _, v := range n.Pipe.Decl {
					varName := v.Ident[0] // e.g. "$var"
					// Reconstruct the declaration action text.
					info.varDefs[varName] = "{{" + n.Pipe.String() + "}}"
				}
			}

		case *parse.IfNode:
			walkBranchForBoundaries(&n.BranchNode, parse.NodeIf, wrappers, info)

		case *parse.RangeNode:
			walkBranchForBoundaries(&n.BranchNode, parse.NodeRange, wrappers, info)

		case *parse.WithNode:
			walkBranchForBoundaries(&n.BranchNode, parse.NodeWith, wrappers, info)
		}
	}
}

// walkBranchForBoundaries walks if/range/with branch nodes looking for
// --- boundaries in their bodies. If found, the block's open/close
// actions are added to the wrapper stack for inner boundaries.
func walkBranchForBoundaries(br *parse.BranchNode, nodeType parse.NodeType, wrappers []blockWrapper, info *docSplitInfo) {
	// Check if the body or else-body contain --- separators.
	var keyword string
	switch nodeType {
	case parse.NodeIf:
		keyword = "if"
	case parse.NodeRange:
		keyword = "range"
	case parse.NodeWith:
		keyword = "with"
	}

	open := "{{" + keyword + " " + br.Pipe.String() + "}}\n"
	close := "{{end}}\n"
	w := blockWrapper{open: open, close: close, isRange: nodeType == parse.NodeRange}

	if br.List != nil {
		innerWrappers := append(slices.Clone(wrappers), w)
		walkDocBoundaries(br.List.Nodes, innerWrappers, info)
	}
	if br.ElseList != nil {
		// Start an else chain. The openPrefix accumulates the
		// {{if A}}{{else if B}}... chain so that the entire
		// construct is represented by a single wrapper with one
		// {{end}}.
		openPrefix := "{{" + keyword + " " + br.Pipe.String() + "}}"
		walkElseChain(br.ElseList, openPrefix, wrappers, info)
	}
}

// walkElseChain walks the else branch of an if/with node. When the
// else body is a single IfNode (the {{else if}} sugar), it folds the
// chain into one wrapper so that only one {{end}} is needed. For a
// plain {{else}}, it pushes a wrapper and walks the body normally.
func walkElseChain(elseList *parse.ListNode, openPrefix string, wrappers []blockWrapper, info *docSplitInfo) {
	// {{else if}} sugar: ElseList contains a single IfNode.
	if len(elseList.Nodes) == 1 {
		if innerIf, ok := elseList.Nodes[0].(*parse.IfNode); ok {
			combined := openPrefix + "{{else if " + innerIf.Pipe.String() + "}}"
			w := blockWrapper{open: combined + "\n", close: "{{end}}\n"}

			if innerIf.List != nil {
				innerWrappers := append(slices.Clone(wrappers), w)
				walkDocBoundaries(innerIf.List.Nodes, innerWrappers, info)
			}
			if innerIf.ElseList != nil {
				walkElseChain(innerIf.ElseList, combined, wrappers, info)
			}
			return
		}
	}

	// Plain {{else}}.
	w := blockWrapper{
		open:  openPrefix + "{{else}}\n",
		close: "{{end}}\n",
	}
	innerWrappers := append(slices.Clone(wrappers), w)
	walkDocBoundaries(elseList.Nodes, innerWrappers, info)
}

// mergeChartDocResults merges per-document convertResults from a single
// template file into a single result whose body is a CUE list expression.
// Cross-document if guards become conditional list elements. Cross-document
// range blocks become list.FlattenN([for ... {[...]}], -1).
func mergeChartDocResults(results []*convertResult) *convertResult {
	merged := &convertResult{
		imports:            make(map[string]bool),
		usedHelpers:        make(map[string]HelperDef),
		usedContextObjects: make(map[string]bool),
		fieldRefs:          make(map[string][][]string),
		requiredRefs:       make(map[string][][]string),
		rangeRefs:          make(map[string][][]string),
		defaults:           make(map[string][]fieldDefault),
	}

	for i, r := range results {
		for k, v := range r.imports {
			merged.imports[k] = v
		}
		if r.needsNonzero {
			merged.needsNonzero = true
		}
		for k, v := range r.usedHelpers {
			merged.usedHelpers[k] = v
		}
		for k := range r.usedContextObjects {
			merged.usedContextObjects[k] = true
		}
		for k, v := range r.fieldRefs {
			merged.fieldRefs[k] = append(merged.fieldRefs[k], v...)
		}
		for k, v := range r.requiredRefs {
			merged.requiredRefs[k] = append(merged.requiredRefs[k], v...)
		}
		for k, v := range r.rangeRefs {
			merged.rangeRefs[k] = append(merged.rangeRefs[k], v...)
		}
		for k, v := range r.defaults {
			merged.defaults[k] = append(merged.defaults[k], v...)
		}
		if r.hasDynamicInclude {
			merged.hasDynamicInclude = true
		}

		// Take helper info from the first result (all share the same treeSet).
		if i == 0 {
			merged.helpers = r.helpers
			merged.helperOrder = r.helperOrder
			merged.helperExprs = r.helperExprs
			merged.undefinedHelpers = r.undefinedHelpers
		}
	}

	// Build list body.
	var body bytes.Buffer

	if len(results) == 1 {
		r := results[0]
		docBody := strings.TrimRight(r.body, "\n")
		if docBody == "" {
			merged.body = "[]"
			return merged
		}

		if r.topLevelRange != "" {
			// Single doc with top-level range.
			merged.imports["list"] = true
			body.WriteString("list.FlattenN([")
			body.WriteString(r.topLevelRange)
			body.WriteString(" {[\n")
			for _, line := range strings.Split(r.topLevelRangeBody, "\n") {
				body.WriteString("\t{\n")
				for _, bline := range strings.Split(line, "\n") {
					if bline != "" {
						body.WriteString("\t\t")
						body.WriteString(bline)
						body.WriteByte('\n')
					}
				}
				body.WriteString("\t},\n")
			}
			body.WriteString("]}], -1)")
		} else if len(r.topLevelGuards) > 0 {
			body.WriteString("[\n")
			indent := 1
			for _, guard := range r.topLevelGuards {
				writeIndent(&body, indent)
				fmt.Fprintf(&body, "if %s {\n", guard)
				indent++
			}
			writeIndent(&body, indent)
			body.WriteString("{\n")
			for _, line := range strings.Split(docBody, "\n") {
				writeIndent(&body, indent+1)
				body.WriteString(line)
				body.WriteByte('\n')
			}
			writeIndent(&body, indent)
			body.WriteString("},\n")
			for j := len(r.topLevelGuards) - 1; j >= 0; j-- {
				writeIndent(&body, j+1)
				body.WriteString("}\n")
			}
			body.WriteString("]")
		} else {
			body.WriteString("[{\n")
			for _, line := range strings.Split(docBody, "\n") {
				body.WriteString("\t")
				body.WriteString(line)
				body.WriteByte('\n')
			}
			body.WriteString("}]")
		}
	} else {
		// Multiple documents â€” group by range blocks.
		type docEntry struct {
			body           string
			topLevelGuards []string
			topLevelRange  string
			rangeBody      string
		}
		var entries []docEntry
		for _, r := range results {
			docBody := strings.TrimRight(r.body, "\n")
			rangeBody := ""
			if r.topLevelRange != "" {
				rangeBody = strings.TrimRight(r.topLevelRangeBody, "\n")
			}
			entries = append(entries, docEntry{
				body:           docBody,
				topLevelGuards: r.topLevelGuards,
				topLevelRange:  r.topLevelRange,
				rangeBody:      rangeBody,
			})
		}

		// Check if all entries share the same topLevelRange.
		hasRange := false
		for _, e := range entries {
			if e.topLevelRange != "" {
				hasRange = true
				break
			}
		}

		if hasRange {
			// Group consecutive entries that share the same
			// topLevelRange into list.FlattenN blocks.
			merged.imports["list"] = true
			body.WriteString("list.FlattenN([\n")
			i := 0
			for i < len(entries) {
				e := entries[i]
				if e.topLevelRange != "" {
					// Find consecutive entries with the same range.
					rangeHeader := e.topLevelRange
					j := i
					for j < len(entries) && entries[j].topLevelRange == rangeHeader {
						j++
					}
					body.WriteString("\t")
					body.WriteString(rangeHeader)
					body.WriteString(" {[\n")
					for k := i; k < j; k++ {
						rb := entries[k].rangeBody
						if rb == "" {
							rb = entries[k].body
						}
						body.WriteString("\t\t{\n")
						for _, line := range strings.Split(rb, "\n") {
							body.WriteString("\t\t\t")
							body.WriteString(line)
							body.WriteByte('\n')
						}
						body.WriteString("\t\t},\n")
					}
					body.WriteString("\t]},\n")
					i = j
				} else if len(e.topLevelGuards) > 0 {
					indent := 1
					for _, guard := range e.topLevelGuards {
						writeIndent(&body, indent)
						fmt.Fprintf(&body, "if %s {\n", guard)
						indent++
					}
					writeIndent(&body, indent)
					body.WriteString("{\n")
					for _, line := range strings.Split(e.body, "\n") {
						writeIndent(&body, indent+1)
						body.WriteString(line)
						body.WriteByte('\n')
					}
					writeIndent(&body, indent)
					body.WriteString("},\n")
					for g := len(e.topLevelGuards) - 1; g >= 0; g-- {
						writeIndent(&body, g+1)
						body.WriteString("}\n")
					}
					i++
				} else {
					body.WriteString("\t{\n")
					for _, line := range strings.Split(e.body, "\n") {
						body.WriteString("\t\t")
						body.WriteString(line)
						body.WriteByte('\n')
					}
					body.WriteString("\t},\n")
					i++
				}
			}
			body.WriteString("], -1)")
		} else {
			body.WriteString("[\n")
			for _, e := range entries {
				if e.body == "" {
					continue
				}
				if len(e.topLevelGuards) > 0 {
					indent := 1
					for _, guard := range e.topLevelGuards {
						writeIndent(&body, indent)
						fmt.Fprintf(&body, "if %s {\n", guard)
						indent++
					}
					writeIndent(&body, indent)
					body.WriteString("{\n")
					for _, line := range strings.Split(e.body, "\n") {
						writeIndent(&body, indent+1)
						body.WriteString(line)
						body.WriteByte('\n')
					}
					writeIndent(&body, indent)
					body.WriteString("},\n")
					for g := len(e.topLevelGuards) - 1; g >= 0; g-- {
						writeIndent(&body, g+1)
						body.WriteString("}\n")
					}
				} else {
					body.WriteString("\t{\n")
					for _, line := range strings.Split(e.body, "\n") {
						body.WriteString("\t\t")
						body.WriteString(line)
						body.WriteByte('\n')
					}
					body.WriteString("\t},\n")
				}
			}
			body.WriteString("]")
		}
	}

	merged.body = body.String()
	return merged
}

// sanitizeIdentifier converts a string to a valid CUE identifier.
func sanitizeIdentifier(name string) string {
	var b strings.Builder
	for i, ch := range name {
		if (ch >= 'a' && ch <= 'z') || (ch >= 'A' && ch <= 'Z') || ch == '_' {
			b.WriteRune(ch)
		} else if ch >= '0' && ch <= '9' {
			if i == 0 {
				b.WriteByte('_')
			}
			b.WriteRune(ch)
		} else {
			b.WriteByte('_')
		}
	}
	s := b.String()
	if s == "" {
		return "_unnamed"
	}
	return s
}

// templateFieldName converts a template filename to a CUE field name.
func templateFieldName(filename string) string {
	stem := strings.TrimSuffix(strings.TrimSuffix(filename, ".yaml"), ".yml")
	return sanitizeIdentifier(stem)
}

// sanitizePackageName converts a chart name to a valid CUE package name.
func sanitizePackageName(name string) string {
	s := sanitizeIdentifier(name)
	// CUE package names must start with a lowercase letter or underscore.
	if len(s) > 0 && s[0] >= 'A' && s[0] <= 'Z' {
		s = "_" + s
	}
	return s
}
